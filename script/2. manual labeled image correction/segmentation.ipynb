{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03318304-b158-41c7-ab65-dfbdfb7d5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join('..', 'utils'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "import file_utilities as fu\n",
    "from QuestionMaster import Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437e7ddd-e81b-4ce3-bfe4-67c2515f3786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File: C:/Users/Ding-Yang/Desktop/Thesis code/Axons-extraction/example data/less_intensive/top_hat/top_hat.tiff\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join('..', 'utils'))\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "import file_utilities as fu\n",
    "from QuestionMaster import Questions\n",
    "\n",
    "file_path = fu.choose_file()\n",
    "\n",
    "# Open the TIFF image\n",
    "bg_remove = tifffile.imread(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab47f0-ef29-43e4-b14a-461882006fb1",
   "metadata": {},
   "source": [
    "# Choose your sigma for initial segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea3d40e-4929-4d61-8b68-97d6e272f3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9ca996229e4da79dde066e272d670c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(interactive(children=(FloatSlider(value=20.0, description='sigma', max=40.0, step=0.5), Checkbo…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simetime it doesn't shows the image in jupyter lab. Use jupyter notebook instead.\n",
    "from skimage.io import imread\n",
    "import pyclesperanto_prototype as cle  # version 0.24.2\n",
    "import napari_simpleitk_image_processing as nsitk  # version 0.4.5\n",
    "import napari\n",
    "from skimage.filters import gaussian, threshold_otsu, sobel\n",
    "from skimage.measure import label\n",
    "import stackview\n",
    "\n",
    "def my_custom_code(image, sigma:float = 1, show_labels: bool = True):\n",
    "    sigma =sigma\n",
    "    binary_image =  cle.greater_or_equal_constant(image, None, sigma)\n",
    "    edge_image = sobel(binary_image)\n",
    "    \n",
    "    if show_labels:\n",
    "        return label(binary_image)\n",
    "    else:\n",
    "        return edge_image * 255 + image \n",
    "\n",
    "stackview.interact(my_custom_code, bg_remove, sigma=(0.0, 40, 0.5),zoom_factor =0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77da09f-a26d-4f62-8202-299adae1f58e",
   "metadata": {},
   "source": [
    "# Determind whether you want to cut your images into small patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f464a72-130a-4d68-a35d-477c0a9bda70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your final sigma (Use the previous as reference):  3.25\n"
     ]
    }
   ],
   "source": [
    "from patchify import patchify, unpatchify\n",
    "\n",
    "image_dataset = np.array(bg_remove)\n",
    "# Ask for sigma value first\n",
    "user_input_sigma = float(input(\"Insert your final sigma (Use the previous as reference): \"))\n",
    "\n",
    "# Preprocess image dataset\n",
    "binary_volume = cle.greater_or_equal_constant(image_dataset, None, user_input_sigma)  # Use napari assistant for binarization\n",
    "markers, num_features = ndi.label(binary_volume)\n",
    "\n",
    "# Filter labels, keeping only those larger than the minimum size\n",
    "min_label_size = 1000\n",
    "filtered_markers = np.zeros_like(markers)\n",
    "unique_labels, label_counts = np.unique(markers, return_counts=True)\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    if count >= min_label_size:\n",
    "        filtered_markers[markers == label] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c42f17-80fc-4fcc-bfba-6f4b972197d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to cut your image into small patches? (If your image has intensive axon, recommend yes.) (y/n):  y\n",
      "What size do you want to cut the image into small patches? (The smaller you cut, more time you need to do the correction. Recommend:1/8 ~ 1/2 width):  1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You get 1 patches with image size (17, 1024, 1024). The complete shape is (1, 17, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Ask if the user wants to cut the image into patches\n",
    "question = Questions(\"Do you want to cut your image into small patches? (If your image has intensive axon, recommend yes.)\")\n",
    "user_input_cut = question.ask_question(input_type='yes_no')\n",
    "\n",
    "if user_input_cut:\n",
    "    valid_patch_size = False  # Initialize a flag for valid input\n",
    "\n",
    "    while not valid_patch_size:\n",
    "        # Ask for patch size\n",
    "        question = Questions(\"What size do you want to cut the image into small patches? (The smaller you cut, more time you need to do the correction. Recommend:1/8 ~ 1/2 width)\")\n",
    "        patch_size = question.ask_question(input_type='int')\n",
    "\n",
    "        # Check if the patch size divides the image size evenly\n",
    "        if image_dataset.shape[1] % patch_size == 0:\n",
    "            valid_patch_size = True  # Set the flag to True if input is valid\n",
    "\n",
    "            # Create patches for image_dataset\n",
    "            img_patches = patchify(image_dataset, (image_dataset.shape[0], patch_size, patch_size), step=patch_size)\n",
    "            image_dataset = np.reshape(img_patches, (-1, img_patches.shape[3], img_patches.shape[4], img_patches.shape[5]))\n",
    "            \n",
    "            # Create patches for mask_dataset\n",
    "            mask_patches = patchify(filtered_markers, (filtered_markers.shape[0], patch_size, patch_size), step=patch_size)\n",
    "            mask_dataset = np.reshape(mask_patches, (-1, mask_patches.shape[3], mask_patches.shape[4], mask_patches.shape[5]))\n",
    "            \n",
    "            print(f\"You get {image_dataset.shape[0]} patches with image size {image_dataset.shape[1:4]}. The complete shape is {image_dataset.shape}\")  # n_patches, x, y, z\n",
    "        else:\n",
    "            print(f\"The size {patch_size} could not divide {image_dataset.shape[1]} evenly. Please enter a valid size.\")\n",
    "else:\n",
    "    # No patching, use single image\n",
    "    mask_dataset = np.expand_dims(filtered_markers, axis=0)\n",
    "    image_dataset = np.expand_dims(image_dataset, axis=0)\n",
    "    print(f\"You get 1 patch with image size {image_dataset.shape}\") \n",
    "\n",
    "def laplacian_sharpening_3d(image):\n",
    "        laplacian = ndi.laplace(image)\n",
    "        sharpened = image - laplacian\n",
    "        return np.clip(sharpened, 0, 255)\n",
    "sharpened_img_dataset = np.zeros_like(image_dataset, dtype=np.uint8)\n",
    "num_images, depth, height, width = image_dataset.shape  # 確保正確的形狀\n",
    "\n",
    "# Apply laplacian sharpening to each 3D image and store the results\n",
    "for i in range(num_images):\n",
    "        sharpened_img_dataset[i] = laplacian_sharpening_3d(image_dataset[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62c458-ffae-4067-a135-dff57a1fa553",
   "metadata": {},
   "source": [
    "# Start manual correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f806cb-fd38-4221-8b9c-de6b9a56132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the image index to start with (0 to 0):  0\n"
     ]
    }
   ],
   "source": [
    "from napari_editor import ImageEditor\n",
    "editor = ImageEditor(image_dataset, sharpened_img_dataset, mask_dataset)\n",
    "editor.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975f561-75a2-4cda-936c-468b51f8f439",
   "metadata": {},
   "source": [
    "## If you want to take a rest and continue to correct the data next time, you can use this to load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676623c1-d38c-4cb1-8438-3f42963b42a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image_dataset.tiff from C:/Users/Ding-Yang/Desktop/Thesis code/Axons-extraction/example data/less_intensive\\image_dataset.tiff\n",
      "Loaded sharpened_img_dataset.tiff from C:/Users/Ding-Yang/Desktop/Thesis code/Axons-extraction/example data/less_intensive\\sharpened_img_dataset.tiff\n",
      "Loaded mask_dataset.tiff from C:/Users/Ding-Yang/Desktop/Thesis code/Axons-extraction/example data/less_intensive\\mask_dataset.tiff\n",
      "All required files are loaded.\n",
      "All files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from manual_correction_data_loader import choose_directory_and_load_datasets\n",
    "\n",
    "# Usage example:\n",
    "datasets, missing_files = choose_directory_and_load_datasets()\n",
    "if datasets:\n",
    "    if 'image_dataset.tiff' in datasets:\n",
    "        image_dataset = datasets['image_dataset.tiff']\n",
    "    if 'sharpened_img_dataset.tiff' in datasets:\n",
    "        sharpened_img_dataset = datasets['sharpened_img_dataset.tiff']\n",
    "    if 'mask_dataset.tiff' in datasets:\n",
    "        mask_dataset = datasets['mask_dataset.tiff']\n",
    "    \n",
    "    # Now you can proceed with your ImageEditor or other operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3738c3-ef83-4f3e-b9a3-949cd6d2af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "intern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
